# 基于决策树的下雪预测

注：本项目算法部分仅使用numpy，pandas，random，pickle库，为了对决策树加深理解所以并未使用其他机器学习库。

##  1.文件结构

本项目由三个部分组成，分别是数据部分，决策树训练部分，界面设计部分，其组成如下

└─决策树训练

&emsp; &emsp; CART.py   //CART算法实现及模型训练

 &emsp;&emsp;config.py   //参数设置

 &emsp;&emsp;data_read.py   //数据预处理以及数据集划分

&emsp;&emsp; main.py  //主执行函数

 &emsp;&emsp;vail_and_test.py   //验证和预测

└─数据及模型

 &emsp;&emsp;BTree.pickle   //决策树模型

&emsp;&emsp; data.csv

&emsp;&emsp; rate.csv

 &emsp;&emsp;test_data.csv  //测试数据集

 &emsp;&emsp;test_kunming.csv  //原始数据集

└─界面设计

 &emsp;&emsp;Ui_design.py   //各控件实现

&emsp;&emsp; WidgetMain.py   //主界面



## 2.数据处理

### 2.1 数据预处理

?		原始的数据集为**test_kunming.csv**，使用的是昆明市2004年到2017年的数据。

?		**首先为避免数据集中出现nan**，需要对nan数据进行排查，由于该数据集是基于时间排序的，相近的几天天气情况都差不多，所以我们碰到nan数据是可以使它等于前两行该属性数据的平均值。

?		**再解决数据集中正负样本不均匀的情况**，由于昆明市地处较南，虽然海拔较高，但下雪仍不频繁，4869条数据中仅有17条下雪数据，我们把下雪看作是正样本，不下雪看作是负样本，根据正负样本严重不均衡的情况我在这里采用了正样本扩大的方法，具体如下：

?		1.将正样本叠加，直到其数量等于负样本的1/3，数量表达式为$正样本数=\frac{负样本数}{正样本数\times 3}$。

?		2.将此时的正样本全部特征分别乘0.9和1.1，再将这三个正样本集合叠加，得到的正样本集数量就几乎等于负样本集数量。

?		**然后再去掉数据集中对最后影响不大的特征**，首先我们直接排除年月日，因为年月日并不具有泛用性，一天是否下雪应该取决于一天具体的天气情况。然后在剩下的特征中，我们采用**主成分分析（PCA）**的方法，选出7个特征（我在这里选择了7个特征，具体调整**config.py**的**choose_feature**参数），做法如下：

?		1.分割下雪标签和其他特征，下雪标签是我们的结果，不应比较它的特征值。

?		2.数据标准化，这里采用了最大最小标准化。如果不进行标准化，数据值较大的特征其特征值就越大。

?		3.构建协方差方程，获得特征值及其对应的特征，并将其存储到**rate.csv**中。

?		4.基于特征值进行排序，选择前七大特征值的特征，并从上面处理好的数据集中选出这七个标签所对应的所有数据并且加上下雪标签组成新的数据集，并存放在**data.csv**中。

?		现在，我们得到了一组可以直接使用的数据。

### 2.2 划分数据集

?		从**data.csv**中直接读取数据，并采用随机抽取的方法获得训练集，验证集，测试集。其比例大致为31：4：5

并将测试集数据存储为**test_data.csv**留作备用。

## 3.模型训练

?		由于cart算法最后得到的是一颗二叉树，所以我们可以很方便的采用列表来存储训练出来的模型。

### 3.1 根据基尼指数求最小特征





## 4.界面设计



?		

?		
